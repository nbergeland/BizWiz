{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3519ff4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === IMPORTS ===\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import googlemaps\n",
    "import requests\n",
    "import time\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import plotly.express as px\n",
    "from dash import Dash, dcc, html, Input, Output, State\n",
    "import dash_bootstrap_components as dbc\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "from dotenv import load_dotenv\n",
    "import pickle\n",
    "from functools import lru_cache\n",
    "\n",
    "# === LOAD .env VARIABLES ===\n",
    "load_dotenv()\n",
    "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "CENSUS_API_KEY = os.getenv('CENSUS_API_KEY')\n",
    "RENTCAST_API_KEY = os.getenv('RENTCAST_API_KEY')\n",
    "\n",
    "# === GOOGLE MAPS CLIENT ===\n",
    "gmaps = googlemaps.Client(key=GOOGLE_API_KEY)\n",
    "\n",
    "# === GRID GENERATION - GRAND FORKS, ND ===\n",
    "min_lat, max_lat = 47.85, 47.95\n",
    "min_lon, max_lon = -97.15, -97.0\n",
    "grid_spacing = 0.005\n",
    "lats = np.arange(min_lat, max_lat, grid_spacing)\n",
    "lons = np.arange(min_lon, max_lon, grid_spacing)\n",
    "grid_points = [(lat, lon) for lat in lats for lon in lons]\n",
    "\n",
    "# === CACHING SETUP ===\n",
    "CACHE_FILE = 'location_data_cache.pkl'\n",
    "\n",
    "def load_cache():\n",
    "    try:\n",
    "        with open(CACHE_FILE, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    except FileNotFoundError:\n",
    "        return {}\n",
    "\n",
    "def save_cache(cache):\n",
    "    with open(CACHE_FILE, 'wb') as f:\n",
    "        pickle.dump(cache, f)\n",
    "\n",
    "# === DISTANCE FUNCTION IN MILES ===\n",
    "def calculate_distance_miles(lat1, lon1, lat2, lon2):\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    a = sin((lat2-lat1)/2)**2 + cos(lat1) * cos(lat2) * sin((lon2-lon1)/2)**2\n",
    "    c = 2 * asin(sqrt(a))\n",
    "    return c * 3956\n",
    "\n",
    "# === BULK DATA FETCHING ===\n",
    "class LocationDataFetcher:\n",
    "    def __init__(self):\n",
    "        self.cache = load_cache()\n",
    "        self.chickfila_locations = None\n",
    "        self.competitor_locations = {}\n",
    "        self.poi_locations = {}\n",
    "        self.active_listings = []\n",
    "        \n",
    "    def fetch_all_chickfila_locations(self):\n",
    "        \"\"\"Fetch all Chick-fil-A locations in the broader area once\"\"\"\n",
    "        if self.chickfila_locations is not None:\n",
    "            return\n",
    "            \n",
    "        cache_key = 'chickfila_all'\n",
    "        if cache_key in self.cache:\n",
    "            self.chickfila_locations = self.cache[cache_key]\n",
    "            return\n",
    "            \n",
    "        center_lat = (min_lat + max_lat) / 2\n",
    "        center_lon = (min_lon + max_lon) / 2\n",
    "        \n",
    "        try:\n",
    "            # Search in a large radius to get all nearby locations\n",
    "            result = gmaps.places_nearby(\n",
    "                location=(center_lat, center_lon), \n",
    "                radius=50000,  # 50km radius\n",
    "                keyword='chick-fil-a'\n",
    "            )\n",
    "            locations = result['results']\n",
    "            \n",
    "            # Handle pagination if needed\n",
    "            while 'next_page_token' in result:\n",
    "                time.sleep(2)\n",
    "                result = gmaps.places_nearby(\n",
    "                    location=(center_lat, center_lon),\n",
    "                    radius=50000,\n",
    "                    keyword='chick-fil-a',\n",
    "                    page_token=result['next_page_token']\n",
    "                )\n",
    "                locations.extend(result['results'])\n",
    "                \n",
    "            self.chickfila_locations = [(\n",
    "                loc['geometry']['location']['lat'],\n",
    "                loc['geometry']['location']['lng']\n",
    "            ) for loc in locations]\n",
    "            \n",
    "            self.cache[cache_key] = self.chickfila_locations\n",
    "            save_cache(self.cache)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching Chick-fil-A locations: {e}\")\n",
    "            self.chickfila_locations = []\n",
    "    \n",
    "    def fetch_competitor_locations(self):\n",
    "        \"\"\"Fetch all competitor locations once\"\"\"\n",
    "        if self.competitor_locations:\n",
    "            return\n",
    "            \n",
    "        center_lat = (min_lat + max_lat) / 2\n",
    "        center_lon = (min_lon + max_lon) / 2\n",
    "        competitors = ['mcdonalds', 'kfc', 'taco bell', 'burger king', 'subway', 'wendys', 'popeyes']\n",
    "        \n",
    "        for competitor in competitors:\n",
    "            cache_key = f'competitor_{competitor}'\n",
    "            if cache_key in self.cache:\n",
    "                self.competitor_locations[competitor] = self.cache[cache_key]\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                result = gmaps.places_nearby(\n",
    "                    location=(center_lat, center_lon),\n",
    "                    radius=20000,  # 20km radius\n",
    "                    keyword=competitor\n",
    "                )\n",
    "                locations = [(\n",
    "                    loc['geometry']['location']['lat'],\n",
    "                    loc['geometry']['location']['lng']\n",
    "                ) for loc in result['results']]\n",
    "                \n",
    "                self.competitor_locations[competitor] = locations\n",
    "                self.cache[cache_key] = locations\n",
    "                time.sleep(0.2)  # Rate limiting\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching {competitor} locations: {e}\")\n",
    "                self.competitor_locations[competitor] = []\n",
    "        \n",
    "        save_cache(self.cache)\n",
    "    \n",
    "    def fetch_poi_locations(self):\n",
    "        \"\"\"Fetch points of interest once\"\"\"\n",
    "        if self.poi_locations:\n",
    "            return\n",
    "            \n",
    "        center_lat = (min_lat + max_lat) / 2\n",
    "        center_lon = (min_lon + max_lon) / 2\n",
    "        poi_types = [\n",
    "            ('university', 'university', 10),\n",
    "            ('shopping_mall', 'shopping_mall', 5), \n",
    "            ('store', 'store', 2),\n",
    "            ('restaurant', 'restaurant', 1)\n",
    "        ]\n",
    "        \n",
    "        for poi_name, poi_type, weight in poi_types:\n",
    "            cache_key = f'poi_{poi_name}'\n",
    "            if cache_key in self.cache:\n",
    "                self.poi_locations[poi_name] = self.cache[cache_key]\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                if poi_name == 'university':\n",
    "                    result = gmaps.places_nearby(\n",
    "                        location=(center_lat, center_lon),\n",
    "                        radius=20000,\n",
    "                        keyword='university'\n",
    "                    )\n",
    "                else:\n",
    "                    result = gmaps.places_nearby(\n",
    "                        location=(center_lat, center_lon),\n",
    "                        radius=20000,\n",
    "                        type=poi_type\n",
    "                    )\n",
    "                    \n",
    "                locations = [(\n",
    "                    loc['geometry']['location']['lat'],\n",
    "                    loc['geometry']['location']['lng'],\n",
    "                    weight\n",
    "                ) for loc in result['results']]\n",
    "                \n",
    "                self.poi_locations[poi_name] = locations\n",
    "                self.cache[cache_key] = locations\n",
    "                time.sleep(0.2)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching {poi_name} locations: {e}\")\n",
    "                self.poi_locations[poi_name] = []\n",
    "        \n",
    "        save_cache(self.cache)\n",
    "\n",
    "    def fetch_rental_listings(self):\n",
    "        \"\"\"Fetch rental listings once\"\"\"\n",
    "        if self.active_listings:\n",
    "            return\n",
    "            \n",
    "        cache_key = 'rental_listings'\n",
    "        if cache_key in self.cache:\n",
    "            # Check if cache is recent (less than 24 hours old)\n",
    "            cache_time = self.cache.get(f'{cache_key}_timestamp', 0)\n",
    "            if time.time() - cache_time < 86400:  # 24 hours\n",
    "                self.active_listings = self.cache[cache_key]\n",
    "                return\n",
    "        \n",
    "        try:\n",
    "            url = \"https://api.rentcast.io/v1/listings/rental/long-term\"\n",
    "            headers = {\"X-Api-Key\": RENTCAST_API_KEY}\n",
    "            params = {\"city\": \"Grand Forks\", \"state\": \"ND\", \"status\": \"active\", \"limit\": 500}\n",
    "            response = requests.get(url, headers=headers, params=params)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                self.active_listings = response.json().get('listings', [])\n",
    "                self.cache[cache_key] = self.active_listings\n",
    "                self.cache[f'{cache_key}_timestamp'] = time.time()\n",
    "                save_cache(self.cache)\n",
    "            else:\n",
    "                self.active_listings = []\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching rental listings: {e}\")\n",
    "            self.active_listings = []\n",
    "\n",
    "    @lru_cache(maxsize=1000)\n",
    "    def get_demographics_cached(self, lat_rounded, lon_rounded):\n",
    "        \"\"\"Cache demographics by rounded coordinates to avoid duplicate census calls\"\"\"\n",
    "        try:\n",
    "            fcc_url = f\"https://geo.fcc.gov/api/census/block/find?latitude={lat_rounded}&longitude={lon_rounded}&format=json\"\n",
    "            fcc_response = requests.get(fcc_url)\n",
    "            fips = fcc_response.json()['Block']['FIPS'][:11]\n",
    "            \n",
    "            url = f\"https://api.census.gov/data/2020/acs/acs5?get=B01003_001E,B19013_001E,B01002_001E&for=tract:{fips[5:11]}&in=state:{fips[:2]}+county:{fips[2:5]}&key={CENSUS_API_KEY}\"\n",
    "            data = requests.get(url).json()[1]\n",
    "            \n",
    "            return {\n",
    "                'population': int(data[0]), \n",
    "                'median_income': int(data[1]), \n",
    "                'median_age': float(data[2])\n",
    "            }\n",
    "        except:\n",
    "            return {'population': 5000, 'median_income': 45000, 'median_age': 28}\n",
    "\n",
    "    def calculate_features_for_point(self, lat, lon):\n",
    "        \"\"\"Calculate all features for a single point using cached data\"\"\"\n",
    "        # Round coordinates for demographic caching (census tracts don't change much)\n",
    "        lat_rounded = round(lat, 3)\n",
    "        lon_rounded = round(lon, 3)\n",
    "        \n",
    "        # Chick-fil-A proximity\n",
    "        if self.chickfila_locations:\n",
    "            distances_to_chickfila = [\n",
    "                calculate_distance_miles(lat, lon, c_lat, c_lon) \n",
    "                for c_lat, c_lon in self.chickfila_locations\n",
    "            ]\n",
    "            chick_count = len([d for d in distances_to_chickfila if d <= 5])  # Within 5 miles\n",
    "            nearest_chickfila = min(distances_to_chickfila) if distances_to_chickfila else 30\n",
    "        else:\n",
    "            chick_count, nearest_chickfila = 0, 30\n",
    "        \n",
    "        # Fast food competition\n",
    "        competition_count = 0\n",
    "        for competitor, locations in self.competitor_locations.items():\n",
    "            nearby_competitors = [\n",
    "                1 for c_lat, c_lon in locations \n",
    "                if calculate_distance_miles(lat, lon, c_lat, c_lon) <= 2  # Within 2 miles\n",
    "            ]\n",
    "            competition_count += len(nearby_competitors)\n",
    "        \n",
    "        # Foot traffic score\n",
    "        foot_traffic = 0\n",
    "        for poi_type, locations in self.poi_locations.items():\n",
    "            for p_lat, p_lon, weight in locations:\n",
    "                if calculate_distance_miles(lat, lon, p_lat, p_lon) <= 1:  # Within 1 mile\n",
    "                    foot_traffic += weight\n",
    "        \n",
    "        # Demographics (cached)\n",
    "        demographics = self.get_demographics_cached(lat_rounded, lon_rounded)\n",
    "        \n",
    "        # Rental data\n",
    "        nearby_listings = []\n",
    "        for listing in self.active_listings:\n",
    "            if listing.get('latitude') and listing.get('longitude'):\n",
    "                distance = calculate_distance_miles(\n",
    "                    lat, lon, listing['latitude'], listing['longitude']\n",
    "                )\n",
    "                if distance <= 1:  # Within 1 mile\n",
    "                    nearby_listings.append(listing['price'])\n",
    "        \n",
    "        active_listings_count = len(nearby_listings)\n",
    "        avg_rent = np.mean(nearby_listings) if nearby_listings else 0\n",
    "        \n",
    "        # Zoning (randomized for demo)\n",
    "        import random\n",
    "        zoning = random.choice([True, False])\n",
    "        \n",
    "        return {\n",
    "            'latitude': lat,\n",
    "            'longitude': lon,\n",
    "            'chickfila_count_nearby': chick_count,\n",
    "            'distance_to_chickfila': nearest_chickfila,\n",
    "            'fast_food_competition': competition_count,\n",
    "            'foot_traffic_score': foot_traffic,\n",
    "            'population': demographics['population'],\n",
    "            'median_income': demographics['median_income'],\n",
    "            'median_age': demographics['median_age'],\n",
    "            'rent_per_sqft': 12.50,  # Fixed for now\n",
    "            'zoning_compliant': int(zoning),\n",
    "            'active_listings_within_1_mile': active_listings_count,\n",
    "            'average_nearby_rent': avg_rent\n",
    "        }\n",
    "\n",
    "# === MAIN DATA COLLECTION ===\n",
    "def collect_location_data():\n",
    "    fetcher = LocationDataFetcher()\n",
    "    \n",
    "    print(\"Fetching bulk data...\")\n",
    "    fetcher.fetch_all_chickfila_locations()\n",
    "    print(f\"Found {len(fetcher.chickfila_locations)} Chick-fil-A locations\")\n",
    "    \n",
    "    fetcher.fetch_competitor_locations()\n",
    "    total_competitors = sum(len(locs) for locs in fetcher.competitor_locations.values())\n",
    "    print(f\"Found {total_competitors} competitor locations\")\n",
    "    \n",
    "    fetcher.fetch_poi_locations()\n",
    "    total_pois = sum(len(locs) for locs in fetcher.poi_locations.values())\n",
    "    print(f\"Found {total_pois} points of interest\")\n",
    "    \n",
    "    fetcher.fetch_rental_listings()\n",
    "    print(f\"Found {len(fetcher.active_listings)} rental listings\")\n",
    "    \n",
    "    print(\"Processing grid points...\")\n",
    "    feature_list = []\n",
    "    \n",
    "    for idx, (lat, lon) in enumerate(grid_points):\n",
    "        if idx % 10 == 0:  # Progress update every 10 points\n",
    "            print(f\"Processing {idx+1}/{len(grid_points)}: {lat:.4f}, {lon:.4f}\")\n",
    "        \n",
    "        features = fetcher.calculate_features_for_point(lat, lon)\n",
    "        feature_list.append(features)\n",
    "        \n",
    "        # Minimal delay to be respectful to APIs\n",
    "        if idx % 50 == 0:  # Only sleep every 50 points\n",
    "            time.sleep(0.1)\n",
    "    \n",
    "    return pd.DataFrame(feature_list)\n",
    "\n",
    "# === DATA PROCESSING ===\n",
    "print(\"Starting data collection...\")\n",
    "df = collect_location_data()\n",
    "\n",
    "# Calculate derived features\n",
    "df['chick_fil_a_advantage'] = np.where(\n",
    "    (df['distance_to_chickfila'] > 1) & (df['distance_to_chickfila'] < 5), \n",
    "    1000 / df['distance_to_chickfila'], \n",
    "    0\n",
    ")\n",
    "df['youth_factor'] = np.where(df['median_age'] < 30, 1.5, 1.0)\n",
    "\n",
    "# Revenue calculation\n",
    "df['estimated_revenue'] = (\n",
    "    df['population'] * 0.4 +\n",
    "    df['median_income'] * 0.0003 +\n",
    "    df['foot_traffic_score'] * 200 +\n",
    "    df['chick_fil_a_advantage'] * 500 +\n",
    "    df['youth_factor'] * 1000 +\n",
    "    df['active_listings_within_1_mile'] * 100 -\n",
    "    df['fast_food_competition'] * 300 -\n",
    "    df['average_nearby_rent'] * 0.1 -\n",
    "    df['rent_per_sqft'] * 100\n",
    ")\n",
    "df['estimated_revenue'] = np.maximum(df['estimated_revenue'], 0)\n",
    "\n",
    "# Model training\n",
    "X = df.drop(columns=['latitude', 'longitude', 'estimated_revenue'])\n",
    "X = X.replace([np.inf, -np.inf], np.nan).fillna(X.mean())\n",
    "y = df['estimated_revenue']\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=150, random_state=42, max_depth=10)\n",
    "model.fit(X, y)\n",
    "df['predicted_revenue'] = model.predict(X)\n",
    "\n",
    "print(f\"Data collection complete. Processed {len(df)} locations.\")\n",
    "\n",
    "# === DASH APP ===\n",
    "app = Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "app.layout = dbc.Container([\n",
    "    dbc.Row(dbc.Col(html.H2(\"Optimal Raising Cane's Locations in Grand Forks, ND\"), className=\"text-center my-4\")),\n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            html.Label(\"Minimum Predicted Revenue:\"),\n",
    "            dcc.Slider(id='revenue-slider', min=0, max=df['predicted_revenue'].max(), step=500, value=df['predicted_revenue'].quantile(0.7)),\n",
    "            html.Label(\"Maximum Distance to Chick-fil-A (miles):\"),\n",
    "            dcc.Slider(id='chickfila-distance-slider', min=0, max=30, step=1, value=5),\n",
    "            html.Label(\"Minimum Foot Traffic Score:\"),\n",
    "            dcc.Slider(id='traffic-slider', min=0, max=df['foot_traffic_score'].max(), step=5, value=0),\n",
    "            html.Label(\"Zoning Compliance:\"),\n",
    "            dcc.RadioItems(id='zoning-radio', options=[{'label': 'All Locations', 'value': 'all'}, {'label': 'Only Compliant', 'value': 'compliant'}], value='compliant'),\n",
    "            html.Div(id='location-stats', className=\"mt-4 p-3 bg-light rounded\")\n",
    "        ], width=3),\n",
    "        dbc.Col(dcc.Graph(id='revenue-map', style={'height': '80vh'}), width=9)\n",
    "    ])\n",
    "], fluid=True)\n",
    "\n",
    "@app.callback(\n",
    "    [Output('revenue-map', 'figure'), Output('location-stats', 'children')],\n",
    "    [Input('revenue-slider', 'value'), Input('chickfila-distance-slider', 'value'), Input('traffic-slider', 'value'), Input('zoning-radio', 'value')]\n",
    ")\n",
    "def update_map(min_revenue, max_chickfila_distance, min_traffic, zoning_filter):\n",
    "    filtered = df[\n",
    "        (df['predicted_revenue'] >= min_revenue) &\n",
    "        (df['distance_to_chickfila'] <= max_chickfila_distance) &\n",
    "        (df['foot_traffic_score'] >= min_traffic)\n",
    "    ]\n",
    "    if zoning_filter == 'compliant':\n",
    "        filtered = filtered[filtered['zoning_compliant'] == 1]\n",
    "    \n",
    "    fig = px.scatter_mapbox(\n",
    "        filtered, lat='latitude', lon='longitude', size='predicted_revenue', color='predicted_revenue',\n",
    "        color_continuous_scale='RdYlGn', size_max=20, zoom=12, mapbox_style='carto-positron'\n",
    "    )\n",
    "    \n",
    "    if len(filtered) > 0:\n",
    "        best = filtered.loc[filtered['predicted_revenue'].idxmax()]\n",
    "        stats = html.Div([\n",
    "            html.H5(\"Top Location\"),\n",
    "            html.P(f\"Latitude: {best['latitude']:.4f}\"),\n",
    "            html.P(f\"Longitude: {best['longitude']:.4f}\"),\n",
    "            html.P(f\"Predicted Revenue: ${best['predicted_revenue']:,.0f}\"),\n",
    "            html.P(f\"Distance to Chick-fil-A: {best['distance_to_chickfila']:.1f} miles\"),\n",
    "            html.P(f\"Competition: {best['fast_food_competition']}\"),\n",
    "            html.P(f\"Foot Traffic: {best['foot_traffic_score']}\"),\n",
    "            html.P(f\"Active Listings (1 mile): {best['active_listings_within_1_mile']}\"),\n",
    "            html.P(f\"Average Rent Nearby: ${best['average_nearby_rent']:,.0f}\")\n",
    "        ])\n",
    "    else:\n",
    "        stats = html.P(\"No locations match your filters.\")\n",
    "    \n",
    "    return fig, stats\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
