{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ffb6aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting commercial location analysis...\n",
      "Fetching bulk data...\n",
      "API calls today: 1\n",
      "Found 2 Chick-fil-A locations\n",
      "API calls today: 2\n",
      "API calls today: 3\n",
      "API calls today: 4\n",
      "API calls today: 5\n",
      "API calls today: 6\n",
      "API calls today: 7\n",
      "API calls today: 8\n",
      "Found 46 competitor locations\n",
      "API calls today: 9\n",
      "API calls today: 10\n",
      "API calls today: 11\n",
      "API calls today: 12\n",
      "API calls today: 13\n",
      "API calls today: 14\n",
      "API calls today: 15\n",
      "API calls today: 16\n",
      "API calls today: 17\n",
      "API calls today: 18\n",
      "API calls today: 19\n",
      "API calls today: 20\n",
      "Found 214 points of interest\n",
      "Found 0 rental listings\n",
      "Fetching road data from OpenStreetMap...\n",
      "Found 1698 road points\n",
      "Found 1698 road points\n",
      "Processing grid points...\n",
      "Processing 1/651: 47.8500, -97.1500\n",
      "Processing 11/651: 47.8500, -97.1000\n",
      "Processing 21/651: 47.8500, -97.0500\n",
      "Processing 31/651: 47.8500, -97.0000\n",
      "Processing 41/651: 47.8550, -97.1050\n",
      "Processing 51/651: 47.8550, -97.0550\n",
      "Processing 61/651: 47.8550, -97.0050\n",
      "Processing 71/651: 47.8600, -97.1100\n",
      "Processing 81/651: 47.8600, -97.0600\n",
      "Processing 91/651: 47.8600, -97.0100\n",
      "Processing 101/651: 47.8650, -97.1150\n",
      "Processing 111/651: 47.8650, -97.0650\n",
      "Processing 121/651: 47.8650, -97.0150\n",
      "Processing 131/651: 47.8700, -97.1200\n",
      "Processing 141/651: 47.8700, -97.0700\n",
      "Processing 151/651: 47.8700, -97.0200\n",
      "Processing 161/651: 47.8750, -97.1250\n",
      "Processing 171/651: 47.8750, -97.0750\n",
      "Processing 181/651: 47.8750, -97.0250\n",
      "Processing 191/651: 47.8800, -97.1300\n",
      "Processing 201/651: 47.8800, -97.0800\n",
      "Processing 211/651: 47.8800, -97.0300\n",
      "Processing 221/651: 47.8850, -97.1350\n",
      "Processing 231/651: 47.8850, -97.0850\n",
      "Processing 241/651: 47.8850, -97.0350\n",
      "Processing 251/651: 47.8900, -97.1400\n",
      "Processing 261/651: 47.8900, -97.0900\n",
      "Processing 271/651: 47.8900, -97.0400\n",
      "Processing 281/651: 47.8950, -97.1450\n",
      "Processing 291/651: 47.8950, -97.0950\n",
      "Processing 301/651: 47.8950, -97.0450\n",
      "Processing 311/651: 47.9000, -97.1500\n",
      "Processing 321/651: 47.9000, -97.1000\n",
      "Processing 331/651: 47.9000, -97.0500\n",
      "Processing 341/651: 47.9000, -97.0000\n",
      "Processing 351/651: 47.9050, -97.1050\n",
      "Processing 361/651: 47.9050, -97.0550\n",
      "Processing 371/651: 47.9050, -97.0050\n",
      "Processing 381/651: 47.9100, -97.1100\n",
      "Processing 391/651: 47.9100, -97.0600\n",
      "Processing 401/651: 47.9100, -97.0100\n",
      "Processing 411/651: 47.9150, -97.1150\n",
      "Processing 421/651: 47.9150, -97.0650\n",
      "Processing 431/651: 47.9150, -97.0150\n",
      "Processing 441/651: 47.9200, -97.1200\n",
      "Processing 451/651: 47.9200, -97.0700\n",
      "Processing 461/651: 47.9200, -97.0200\n",
      "Processing 471/651: 47.9250, -97.1250\n",
      "Processing 481/651: 47.9250, -97.0750\n",
      "Processing 491/651: 47.9250, -97.0250\n",
      "Processing 501/651: 47.9300, -97.1300\n",
      "Processing 511/651: 47.9300, -97.0800\n",
      "Processing 521/651: 47.9300, -97.0300\n",
      "Processing 531/651: 47.9350, -97.1350\n",
      "Processing 541/651: 47.9350, -97.0850\n",
      "Processing 551/651: 47.9350, -97.0350\n",
      "Processing 561/651: 47.9400, -97.1400\n",
      "Processing 571/651: 47.9400, -97.0900\n",
      "Processing 581/651: 47.9400, -97.0400\n",
      "Processing 591/651: 47.9450, -97.1450\n",
      "Processing 601/651: 47.9450, -97.0950\n",
      "Processing 611/651: 47.9450, -97.0450\n",
      "Processing 621/651: 47.9500, -97.1500\n",
      "Processing 631/651: 47.9500, -97.1000\n",
      "Processing 641/651: 47.9500, -97.0500\n",
      "Processing 651/651: 47.9500, -97.0000\n",
      "Filtered out 0 residential-biased locations\n",
      "Kept 651 commercially viable locations\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "                     feature  importance\n",
      "14     chick_fil_a_advantage    0.726961\n",
      "3   commercial_traffic_score    0.163084\n",
      "1      distance_to_chickfila    0.105147\n",
      "2      fast_food_competition    0.002098\n",
      "0     chickfila_count_nearby    0.000912\n",
      "4   road_accessibility_score    0.000593\n",
      "10          zoning_compliant    0.000260\n",
      "6                 population    0.000234\n",
      "7              median_income    0.000167\n",
      "8                 median_age    0.000155\n",
      "\n",
      "Commercial location analysis complete. Processed 651 locations.\n",
      "Top predicted revenue: $202,805\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x337d62300>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === IMPORTS ===\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import googlemaps\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import datetime\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import plotly.express as px\n",
    "from dash import Dash, dcc, html, Input, Output, State\n",
    "import dash_bootstrap_components as dbc\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "from dotenv import load_dotenv\n",
    "import pickle\n",
    "from functools import lru_cache\n",
    "\n",
    "# === LOAD .env VARIABLES ===\n",
    "load_dotenv()\n",
    "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "CENSUS_API_KEY = os.getenv('CENSUS_API_KEY')\n",
    "RENTCAST_API_KEY = os.getenv('RENTCAST_API_KEY')\n",
    "\n",
    "# === GOOGLE MAPS CLIENT ===\n",
    "gmaps = googlemaps.Client(key=GOOGLE_API_KEY)\n",
    "\n",
    "# === GRID GENERATION - GRAND FORKS, ND ===\n",
    "min_lat, max_lat = 47.85, 47.95\n",
    "min_lon, max_lon = -97.15, -97.0\n",
    "grid_spacing = 0.005\n",
    "lats = np.arange(min_lat, max_lat, grid_spacing)\n",
    "lons = np.arange(min_lon, max_lon, grid_spacing)\n",
    "grid_points = [(lat, lon) for lat in lats for lon in lons]\n",
    "\n",
    "# === CACHING SETUP ===\n",
    "CACHE_FILE = 'location_data_cache.pkl'\n",
    "USAGE_FILE = 'api_usage.json'\n",
    "\n",
    "def load_cache():\n",
    "    try:\n",
    "        with open(CACHE_FILE, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    except FileNotFoundError:\n",
    "        return {}\n",
    "\n",
    "def save_cache(cache):\n",
    "    with open(CACHE_FILE, 'wb') as f:\n",
    "        pickle.dump(cache, f)\n",
    "\n",
    "def load_api_usage():\n",
    "    try:\n",
    "        with open(USAGE_FILE, 'r') as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        return {'daily_calls': 0, 'date': str(datetime.date.today())}\n",
    "\n",
    "def save_api_usage(usage):\n",
    "    with open(USAGE_FILE, 'w') as f:\n",
    "        json.dump(usage, f)\n",
    "\n",
    "def track_api_call():\n",
    "    \"\"\"Track API calls to monitor usage\"\"\"\n",
    "    usage = load_api_usage()\n",
    "    today = str(datetime.date.today())\n",
    "    \n",
    "    if usage['date'] != today:\n",
    "        usage = {'daily_calls': 0, 'date': today}\n",
    "    \n",
    "    usage['daily_calls'] += 1\n",
    "    save_api_usage(usage)\n",
    "    \n",
    "    print(f\"API calls today: {usage['daily_calls']}\")\n",
    "    return usage['daily_calls']\n",
    "\n",
    "# === DISTANCE FUNCTION IN MILES ===\n",
    "def calculate_distance_miles(lat1, lon1, lat2, lon2):\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    a = sin((lat2-lat1)/2)**2 + cos(lat1) * cos(lat2) * sin((lon2-lon1)/2)**2\n",
    "    c = 2 * asin(sqrt(a))\n",
    "    return c * 3956\n",
    "\n",
    "# === ROAD DATA FROM OPENSTREETMAP (FREE) ===\n",
    "def fetch_road_data():\n",
    "    \"\"\"Fetch major roads using OpenStreetMap Overpass API (free)\"\"\"\n",
    "    cache_key = 'osm_roads'\n",
    "    cache = load_cache()\n",
    "    \n",
    "    if cache_key in cache:\n",
    "        return cache[cache_key]\n",
    "    \n",
    "    overpass_url = \"http://overpass-api.de/api/interpreter\"\n",
    "    overpass_query = f\"\"\"\n",
    "    [out:json][timeout:25];\n",
    "    (\n",
    "      way[\"highway\"~\"^(trunk|primary|secondary|trunk_link|primary_link)$\"]({min_lat},{min_lon},{max_lat},{max_lon});\n",
    "    );\n",
    "    out geom;\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        print(\"Fetching road data from OpenStreetMap...\")\n",
    "        response = requests.get(overpass_url, params={'data': overpass_query})\n",
    "        roads_data = response.json()\n",
    "        \n",
    "        # Extract road coordinates\n",
    "        road_points = []\n",
    "        for way in roads_data.get('elements', []):\n",
    "            if 'geometry' in way:\n",
    "                for point in way['geometry']:\n",
    "                    road_points.append((point['lat'], point['lon']))\n",
    "        \n",
    "        cache[cache_key] = road_points\n",
    "        save_cache(cache)\n",
    "        print(f\"Found {len(road_points)} road points\")\n",
    "        return road_points\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching road data: {e}\")\n",
    "        return []\n",
    "\n",
    "# === IMPROVED DATA FETCHER ===\n",
    "class CommercialLocationDataFetcher:\n",
    "    def __init__(self):\n",
    "        self.cache = load_cache()\n",
    "        self.chickfila_locations = None\n",
    "        self.competitor_locations = {}\n",
    "        self.poi_locations = {}\n",
    "        self.active_listings = []\n",
    "        self.road_points = []\n",
    "        \n",
    "    def fetch_all_chickfila_locations(self):\n",
    "        \"\"\"Fetch all Chick-fil-A locations in the broader area once\"\"\"\n",
    "        if self.chickfila_locations is not None:\n",
    "            return\n",
    "            \n",
    "        cache_key = 'chickfila_all'\n",
    "        if cache_key in self.cache:\n",
    "            self.chickfila_locations = self.cache[cache_key]\n",
    "            return\n",
    "            \n",
    "        center_lat = (min_lat + max_lat) / 2\n",
    "        center_lon = (min_lon + max_lon) / 2\n",
    "        \n",
    "        try:\n",
    "            track_api_call()\n",
    "            result = gmaps.places_nearby(\n",
    "                location=(center_lat, center_lon), \n",
    "                radius=50000,  # 50km radius\n",
    "                keyword='chick-fil-a'\n",
    "            )\n",
    "            locations = result['results']\n",
    "            \n",
    "            # Handle pagination if needed\n",
    "            while 'next_page_token' in result:\n",
    "                time.sleep(2)\n",
    "                track_api_call()\n",
    "                result = gmaps.places_nearby(\n",
    "                    location=(center_lat, center_lon),\n",
    "                    radius=50000,\n",
    "                    keyword='chick-fil-a',\n",
    "                    page_token=result['next_page_token']\n",
    "                )\n",
    "                locations.extend(result['results'])\n",
    "                \n",
    "            self.chickfila_locations = [(\n",
    "                loc['geometry']['location']['lat'],\n",
    "                loc['geometry']['location']['lng']\n",
    "            ) for loc in locations]\n",
    "            \n",
    "            self.cache[cache_key] = self.chickfila_locations\n",
    "            save_cache(self.cache)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching Chick-fil-A locations: {e}\")\n",
    "            self.chickfila_locations = []\n",
    "    \n",
    "    def fetch_competitor_locations(self):\n",
    "        \"\"\"Fetch all competitor locations once\"\"\"\n",
    "        if self.competitor_locations:\n",
    "            return\n",
    "            \n",
    "        center_lat = (min_lat + max_lat) / 2\n",
    "        center_lon = (min_lon + max_lon) / 2\n",
    "        competitors = ['mcdonalds', 'kfc', 'taco bell', 'burger king', 'subway', 'wendys', 'popeyes']\n",
    "        \n",
    "        for competitor in competitors:\n",
    "            cache_key = f'competitor_{competitor}'\n",
    "            if cache_key in self.cache:\n",
    "                self.competitor_locations[competitor] = self.cache[cache_key]\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                track_api_call()\n",
    "                result = gmaps.places_nearby(\n",
    "                    location=(center_lat, center_lon),\n",
    "                    radius=20000,  # 20km radius\n",
    "                    keyword=competitor\n",
    "                )\n",
    "                locations = [(\n",
    "                    loc['geometry']['location']['lat'],\n",
    "                    loc['geometry']['location']['lng']\n",
    "                ) for loc in result['results']]\n",
    "                \n",
    "                self.competitor_locations[competitor] = locations\n",
    "                self.cache[cache_key] = locations\n",
    "                time.sleep(0.2)  # Rate limiting\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching {competitor} locations: {e}\")\n",
    "                self.competitor_locations[competitor] = []\n",
    "        \n",
    "        save_cache(self.cache)\n",
    "    \n",
    "    def fetch_commercial_poi_locations(self):\n",
    "        \"\"\"Fetch commercial-focused points of interest\"\"\"\n",
    "        if self.poi_locations:\n",
    "            return\n",
    "            \n",
    "        center_lat = (min_lat + max_lat) / 2\n",
    "        center_lon = (min_lon + max_lon) / 2\n",
    "        \n",
    "        # Commercial-focused POI with higher weights for business viability\n",
    "        poi_types = [\n",
    "            ('shopping_mall', 'shopping_mall', 50),      # High traffic generators\n",
    "            ('gas_station', 'gas_station', 30),         # High visibility locations\n",
    "            ('bank', 'bank', 25),                       # Commercial corridors\n",
    "            ('pharmacy', 'pharmacy', 20),               # Strip mall locations\n",
    "            ('supermarket', 'supermarket', 40),         # Anchor stores\n",
    "            ('hospital', 'hospital', 30),               # High traffic\n",
    "            ('university', 'university', 35),           # Student traffic\n",
    "            ('gym', 'gym', 15),                         # Commercial areas\n",
    "            ('car_dealer', 'car_dealer', 20),           # Commercial strips\n",
    "            ('lodging', 'lodging', 25),                 # Commercial zones\n",
    "            ('store', 'store', 10),                     # General retail\n",
    "            ('restaurant', 'restaurant', 5)             # Food service areas\n",
    "        ]\n",
    "        \n",
    "        for poi_name, poi_type, weight in poi_types:\n",
    "            cache_key = f'poi_{poi_name}'\n",
    "            if cache_key in self.cache:\n",
    "                self.poi_locations[poi_name] = self.cache[cache_key]\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                track_api_call()\n",
    "                if poi_name == 'university':\n",
    "                    result = gmaps.places_nearby(\n",
    "                        location=(center_lat, center_lon),\n",
    "                        radius=25000,  # Larger radius for better coverage\n",
    "                        keyword='university'\n",
    "                    )\n",
    "                else:\n",
    "                    result = gmaps.places_nearby(\n",
    "                        location=(center_lat, center_lon),\n",
    "                        radius=25000,\n",
    "                        type=poi_type\n",
    "                    )\n",
    "                    \n",
    "                locations = [(\n",
    "                    loc['geometry']['location']['lat'],\n",
    "                    loc['geometry']['location']['lng'],\n",
    "                    weight\n",
    "                ) for loc in result['results']]\n",
    "                \n",
    "                self.poi_locations[poi_name] = locations\n",
    "                self.cache[cache_key] = locations\n",
    "                time.sleep(0.2)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching {poi_name} locations: {e}\")\n",
    "                self.poi_locations[poi_name] = []\n",
    "        \n",
    "        save_cache(self.cache)\n",
    "\n",
    "    def fetch_rental_listings(self):\n",
    "        \"\"\"Fetch rental listings once\"\"\"\n",
    "        if self.active_listings:\n",
    "            return\n",
    "            \n",
    "        cache_key = 'rental_listings'\n",
    "        if cache_key in self.cache:\n",
    "            # Check if cache is recent (less than 24 hours old)\n",
    "            cache_time = self.cache.get(f'{cache_key}_timestamp', 0)\n",
    "            if time.time() - cache_time < 86400:  # 24 hours\n",
    "                self.active_listings = self.cache[cache_key]\n",
    "                return\n",
    "        \n",
    "        try:\n",
    "            url = \"https://api.rentcast.io/v1/listings/rental/long-term\"\n",
    "            headers = {\"X-Api-Key\": RENTCAST_API_KEY}\n",
    "            params = {\"city\": \"Grand Forks\", \"state\": \"ND\", \"status\": \"active\", \"limit\": 500}\n",
    "            response = requests.get(url, headers=headers, params=params)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                self.active_listings = response.json().get('listings', [])\n",
    "                self.cache[cache_key] = self.active_listings\n",
    "                self.cache[f'{cache_key}_timestamp'] = time.time()\n",
    "                save_cache(self.cache)\n",
    "            else:\n",
    "                self.active_listings = []\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching rental listings: {e}\")\n",
    "            self.active_listings = []\n",
    "\n",
    "    def fetch_road_data(self):\n",
    "        \"\"\"Load road data from OpenStreetMap\"\"\"\n",
    "        self.road_points = fetch_road_data()\n",
    "\n",
    "    @lru_cache(maxsize=1000)\n",
    "    def get_demographics_cached(self, lat_rounded, lon_rounded):\n",
    "        \"\"\"Cache demographics by rounded coordinates to avoid duplicate census calls\"\"\"\n",
    "        try:\n",
    "            fcc_url = f\"https://geo.fcc.gov/api/census/block/find?latitude={lat_rounded}&longitude={lon_rounded}&format=json\"\n",
    "            fcc_response = requests.get(fcc_url)\n",
    "            fips = fcc_response.json()['Block']['FIPS'][:11]\n",
    "            \n",
    "            url = f\"https://api.census.gov/data/2020/acs/acs5?get=B01003_001E,B19013_001E,B01002_001E&for=tract:{fips[5:11]}&in=state:{fips[:2]}+county:{fips[2:5]}&key={CENSUS_API_KEY}\"\n",
    "            data = requests.get(url).json()[1]\n",
    "            \n",
    "            return {\n",
    "                'population': int(data[0]), \n",
    "                'median_income': int(data[1]), \n",
    "                'median_age': float(data[2])\n",
    "            }\n",
    "        except:\n",
    "            return {'population': 5000, 'median_income': 45000, 'median_age': 28}\n",
    "\n",
    "    def calculate_commercial_viability_score(self, lat, lon):\n",
    "        \"\"\"Calculate commercial viability without additional API calls\"\"\"\n",
    "        \n",
    "        # Commercial foot traffic score (much higher weights)\n",
    "        commercial_traffic = 0\n",
    "        for poi_type, locations in self.poi_locations.items():\n",
    "            if poi_type in ['shopping_mall', 'supermarket', 'gas_station', 'bank']:\n",
    "                for p_lat, p_lon, weight in locations:\n",
    "                    distance = calculate_distance_miles(lat, lon, p_lat, p_lon)\n",
    "                    if distance <= 1:  # Within 1 mile\n",
    "                        commercial_traffic += weight\n",
    "        \n",
    "        # Visibility/accessibility score using pre-fetched road data\n",
    "        road_accessibility = 0\n",
    "        if self.road_points:\n",
    "            nearby_roads = [\n",
    "                1 for r_lat, r_lon in self.road_points\n",
    "                if calculate_distance_miles(lat, lon, r_lat, r_lon) <= 0.2  # Within 0.2 miles\n",
    "            ]\n",
    "            road_accessibility = min(len(nearby_roads) * 5, 50)  # Cap at 50\n",
    "        \n",
    "        # Gas station proximity (indicator of major roads and visibility)\n",
    "        gas_stations = self.poi_locations.get('gas_station', [])\n",
    "        gas_proximity = 0\n",
    "        for g_lat, g_lon, _ in gas_stations:\n",
    "            distance = calculate_distance_miles(lat, lon, g_lat, g_lon)\n",
    "            if distance <= 0.5:  # Within 0.5 miles\n",
    "                gas_proximity += 15\n",
    "        \n",
    "        return {\n",
    "            'commercial_traffic_score': commercial_traffic,\n",
    "            'road_accessibility_score': road_accessibility,\n",
    "            'gas_station_proximity': gas_proximity\n",
    "        }\n",
    "\n",
    "    def detect_residential_bias(self, lat, lon, active_listings_count, population):\n",
    "        \"\"\"Detect if location is heavily residential\"\"\"\n",
    "        \n",
    "        residential_indicators = 0\n",
    "        \n",
    "        # High apartment density\n",
    "        if active_listings_count > 15:\n",
    "            residential_indicators += 10\n",
    "        \n",
    "        # Very high population density (typical of residential areas)\n",
    "        if population > 8000:\n",
    "            residential_indicators += 15\n",
    "        \n",
    "        # Low commercial activity\n",
    "        commercial_nearby = 0\n",
    "        for poi_type in ['gas_station', 'bank', 'shopping_mall']:\n",
    "            locations = self.poi_locations.get(poi_type, [])\n",
    "            for p_lat, p_lon, _ in locations:\n",
    "                if calculate_distance_miles(lat, lon, p_lat, p_lon) <= 0.5:\n",
    "                    commercial_nearby += 1\n",
    "        \n",
    "        if commercial_nearby == 0:\n",
    "            residential_indicators += 10\n",
    "        \n",
    "        return residential_indicators\n",
    "\n",
    "    def calculate_features_for_point(self, lat, lon):\n",
    "        \"\"\"Calculate all features for a single point using cached data\"\"\"\n",
    "        # Round coordinates for demographic caching\n",
    "        lat_rounded = round(lat, 3)\n",
    "        lon_rounded = round(lon, 3)\n",
    "        \n",
    "        # Chick-fil-A proximity\n",
    "        if self.chickfila_locations:\n",
    "            distances_to_chickfila = [\n",
    "                calculate_distance_miles(lat, lon, c_lat, c_lon) \n",
    "                for c_lat, c_lon in self.chickfila_locations\n",
    "            ]\n",
    "            chick_count = len([d for d in distances_to_chickfila if d <= 5])\n",
    "            nearest_chickfila = min(distances_to_chickfila) if distances_to_chickfila else 30\n",
    "        else:\n",
    "            chick_count, nearest_chickfila = 0, 30\n",
    "        \n",
    "        # Fast food competition\n",
    "        competition_count = 0\n",
    "        for competitor, locations in self.competitor_locations.items():\n",
    "            nearby_competitors = [\n",
    "                1 for c_lat, c_lon in locations \n",
    "                if calculate_distance_miles(lat, lon, c_lat, c_lon) <= 2\n",
    "            ]\n",
    "            competition_count += len(nearby_competitors)\n",
    "        \n",
    "        # Commercial viability scores\n",
    "        commercial_scores = self.calculate_commercial_viability_score(lat, lon)\n",
    "        \n",
    "        # Demographics (cached)\n",
    "        demographics = self.get_demographics_cached(lat_rounded, lon_rounded)\n",
    "        \n",
    "        # Rental data\n",
    "        nearby_listings = []\n",
    "        for listing in self.active_listings:\n",
    "            if listing.get('latitude') and listing.get('longitude'):\n",
    "                distance = calculate_distance_miles(\n",
    "                    lat, lon, listing['latitude'], listing['longitude']\n",
    "                )\n",
    "                if distance <= 1:\n",
    "                    nearby_listings.append(listing['price'])\n",
    "        \n",
    "        active_listings_count = len(nearby_listings)\n",
    "        avg_rent = np.mean(nearby_listings) if nearby_listings else 0\n",
    "        \n",
    "        # Residential bias detection\n",
    "        residential_bias = self.detect_residential_bias(\n",
    "            lat, lon, active_listings_count, demographics['population']\n",
    "        )\n",
    "        \n",
    "        # Zoning (randomized for demo)\n",
    "        import random\n",
    "        zoning = random.choice([True, False])\n",
    "        \n",
    "        return {\n",
    "            'latitude': lat,\n",
    "            'longitude': lon,\n",
    "            'chickfila_count_nearby': chick_count,\n",
    "            'distance_to_chickfila': nearest_chickfila,\n",
    "            'fast_food_competition': competition_count,\n",
    "            'commercial_traffic_score': commercial_scores['commercial_traffic_score'],\n",
    "            'road_accessibility_score': commercial_scores['road_accessibility_score'],\n",
    "            'gas_station_proximity': commercial_scores['gas_station_proximity'],\n",
    "            'population': demographics['population'],\n",
    "            'median_income': demographics['median_income'],\n",
    "            'median_age': demographics['median_age'],\n",
    "            'rent_per_sqft': 12.50,\n",
    "            'zoning_compliant': int(zoning),\n",
    "            'active_listings_within_1_mile': active_listings_count,\n",
    "            'average_nearby_rent': avg_rent,\n",
    "            'residential_bias_score': residential_bias\n",
    "        }\n",
    "\n",
    "# === MAIN DATA COLLECTION ===\n",
    "def collect_commercial_location_data():\n",
    "    fetcher = CommercialLocationDataFetcher()\n",
    "    \n",
    "    print(\"Fetching bulk data...\")\n",
    "    fetcher.fetch_all_chickfila_locations()\n",
    "    print(f\"Found {len(fetcher.chickfila_locations)} Chick-fil-A locations\")\n",
    "    \n",
    "    fetcher.fetch_competitor_locations()\n",
    "    total_competitors = sum(len(locs) for locs in fetcher.competitor_locations.values())\n",
    "    print(f\"Found {total_competitors} competitor locations\")\n",
    "    \n",
    "    fetcher.fetch_commercial_poi_locations()\n",
    "    total_pois = sum(len(locs) for locs in fetcher.poi_locations.values())\n",
    "    print(f\"Found {total_pois} points of interest\")\n",
    "    \n",
    "    fetcher.fetch_rental_listings()\n",
    "    print(f\"Found {len(fetcher.active_listings)} rental listings\")\n",
    "    \n",
    "    fetcher.fetch_road_data()\n",
    "    print(f\"Found {len(fetcher.road_points)} road points\")\n",
    "    \n",
    "    print(\"Processing grid points...\")\n",
    "    feature_list = []\n",
    "    \n",
    "    for idx, (lat, lon) in enumerate(grid_points):\n",
    "        if idx % 10 == 0:\n",
    "            print(f\"Processing {idx+1}/{len(grid_points)}: {lat:.4f}, {lon:.4f}\")\n",
    "        \n",
    "        features = fetcher.calculate_features_for_point(lat, lon)\n",
    "        feature_list.append(features)\n",
    "        \n",
    "        # Minimal delay\n",
    "        if idx % 100 == 0:\n",
    "            time.sleep(0.1)\n",
    "    \n",
    "    return pd.DataFrame(feature_list)\n",
    "\n",
    "# === IMPROVED DATA PROCESSING ===\n",
    "print(\"Starting commercial location analysis...\")\n",
    "df = collect_commercial_location_data()\n",
    "\n",
    "# Calculate derived commercial features\n",
    "df['chick_fil_a_advantage'] = np.where(\n",
    "    (df['distance_to_chickfila'] > 2) & (df['distance_to_chickfila'] < 8), \n",
    "    800 / df['distance_to_chickfila'], \n",
    "    0\n",
    ")\n",
    "\n",
    "# Youth factor (important for fast-casual dining)\n",
    "df['youth_factor'] = np.where(df['median_age'] < 35, 800, 0)\n",
    "\n",
    "# Competition clustering advantage (some competition is good)\n",
    "df['competitive_cluster_bonus'] = np.where(\n",
    "    (df['fast_food_competition'] >= 2) & (df['fast_food_competition'] <= 6), \n",
    "    300, \n",
    "    np.where(df['fast_food_competition'] > 6, -200, 0)\n",
    ")\n",
    "\n",
    "# Commercial-focused revenue calculation\n",
    "df['estimated_revenue'] = (\n",
    "    # Commercial factors (high weights)\n",
    "    df['commercial_traffic_score'] * 150 +\n",
    "    df['road_accessibility_score'] * 100 +\n",
    "    df['gas_station_proximity'] * 80 +\n",
    "    df['competitive_cluster_bonus'] +\n",
    "    \n",
    "    # Demographics (moderate weights, focus on income)\n",
    "    df['median_income'] * 0.002 +\n",
    "    df['youth_factor'] +\n",
    "    \n",
    "    # Strategic positioning\n",
    "    df['chick_fil_a_advantage'] * 400 +\n",
    "    \n",
    "    # Penalties for residential bias\n",
    "    df['active_listings_within_1_mile'] * -100 +  # Penalty for apartment density\n",
    "    df['residential_bias_score'] * -150 +         # General residential penalty\n",
    "    np.where(df['population'] > 9000, -500, 0) +  # Very dense residential penalty\n",
    "    \n",
    "    # Zoning compliance bonus\n",
    "    df['zoning_compliant'] * 1200 +\n",
    "    \n",
    "    # Base commercial viability\n",
    "    2000\n",
    ")\n",
    "\n",
    "# Ensure non-negative revenue\n",
    "df['estimated_revenue'] = np.maximum(df['estimated_revenue'], 0)\n",
    "\n",
    "# Filter out locations with high residential bias unless they have strong commercial indicators\n",
    "df['keep_location'] = (\n",
    "    (df['residential_bias_score'] < 20) |  # Low residential bias, or\n",
    "    (df['commercial_traffic_score'] > 50)  # Strong commercial indicators\n",
    ")\n",
    "\n",
    "# Apply filter\n",
    "df_filtered = df[df['keep_location']].copy()\n",
    "\n",
    "print(f\"Filtered out {len(df) - len(df_filtered)} residential-biased locations\")\n",
    "print(f\"Kept {len(df_filtered)} commercially viable locations\")\n",
    "\n",
    "# Model training on filtered data\n",
    "X = df_filtered.drop(columns=[\n",
    "    'latitude', 'longitude', 'estimated_revenue', 'keep_location'\n",
    "]).select_dtypes(include=[np.number])\n",
    "X = X.replace([np.inf, -np.inf], np.nan).fillna(X.mean())\n",
    "y = df_filtered['estimated_revenue']\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=200, random_state=42, max_depth=12)\n",
    "model.fit(X, y)\n",
    "df_filtered['predicted_revenue'] = model.predict(X)\n",
    "\n",
    "# Feature importance analysis\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "print(f\"\\nCommercial location analysis complete. Processed {len(df_filtered)} locations.\")\n",
    "print(f\"Top predicted revenue: ${df_filtered['predicted_revenue'].max():,.0f}\")\n",
    "\n",
    "# === DASH APP ===\n",
    "app = Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "\n",
    "app.layout = dbc.Container([\n",
    "    dbc.Row(dbc.Col(html.H2(\"Optimal Raising Cane's Locations in Grand Forks, ND\"), className=\"text-center my-4\")),\n",
    "    \n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            html.Label(\"Minimum Predicted Revenue:\"),\n",
    "            dcc.Slider(\n",
    "                id='revenue-slider', \n",
    "                min=0, \n",
    "                max=df_filtered['predicted_revenue'].max(), \n",
    "                step=1000, \n",
    "                value=df_filtered['predicted_revenue'].quantile(0.6),\n",
    "                tooltip={\"placement\": \"bottom\", \"always_visible\": True}\n",
    "            ),\n",
    "            \n",
    "            html.Label(\"Maximum Distance to Chick-fil-A (miles):\"),\n",
    "            dcc.Slider(\n",
    "                id='chickfila-distance-slider', \n",
    "                min=0, \n",
    "                max=15, \n",
    "                step=1, \n",
    "                value=8,\n",
    "                tooltip={\"placement\": \"bottom\", \"always_visible\": True}\n",
    "            ),\n",
    "            \n",
    "            html.Label(\"Minimum Commercial Traffic Score:\"),\n",
    "            dcc.Slider(\n",
    "                id='commercial-traffic-slider', \n",
    "                min=0, \n",
    "                max=df_filtered['commercial_traffic_score'].max(), \n",
    "                step=10, \n",
    "                value=20,\n",
    "                tooltip={\"placement\": \"bottom\", \"always_visible\": True}\n",
    "            ),\n",
    "            \n",
    "            html.Label(\"Maximum Fast Food Competition:\"),\n",
    "            dcc.Slider(\n",
    "                id='competition-slider', \n",
    "                min=0, \n",
    "                max=15, \n",
    "                step=1, \n",
    "                value=8,\n",
    "                tooltip={\"placement\": \"bottom\", \"always_visible\": True}\n",
    "            ),\n",
    "            \n",
    "            html.Label(\"Zoning Compliance:\"),\n",
    "            dcc.RadioItems(\n",
    "                id='zoning-radio', \n",
    "                options=[\n",
    "                    {'label': 'All Locations', 'value': 'all'}, \n",
    "                    {'label': 'Only Compliant', 'value': 'compliant'}\n",
    "                ], \n",
    "                value='compliant'\n",
    "            ),\n",
    "            \n",
    "            html.Div(id='location-stats', className=\"mt-4 p-3 bg-light rounded\")\n",
    "        ], width=3),\n",
    "        \n",
    "        dbc.Col([\n",
    "            dcc.Graph(id='revenue-map', style={'height': '80vh'})\n",
    "        ], width=9)\n",
    "    ])\n",
    "], fluid=True)\n",
    "\n",
    "@app.callback(\n",
    "    [Output('revenue-map', 'figure'), Output('location-stats', 'children')],\n",
    "    [Input('revenue-slider', 'value'), \n",
    "     Input('chickfila-distance-slider', 'value'), \n",
    "     Input('commercial-traffic-slider', 'value'),\n",
    "     Input('competition-slider', 'value'),\n",
    "     Input('zoning-radio', 'value')]\n",
    ")\n",
    "def update_map(min_revenue, max_chickfila_distance, min_commercial_traffic, max_competition, zoning_filter):\n",
    "    filtered = df_filtered[\n",
    "        (df_filtered['predicted_revenue'] >= min_revenue) &\n",
    "        (df_filtered['distance_to_chickfila'] <= max_chickfila_distance) &\n",
    "        (df_filtered['commercial_traffic_score'] >= min_commercial_traffic) &\n",
    "        (df_filtered['fast_food_competition'] <= max_competition)\n",
    "    ]\n",
    "    \n",
    "    if zoning_filter == 'compliant':\n",
    "        filtered = filtered[filtered['zoning_compliant'] == 1]\n",
    "    \n",
    "    # Create map\n",
    "    fig = px.scatter_mapbox(\n",
    "        filtered, \n",
    "        lat='latitude', \n",
    "        lon='longitude', \n",
    "        size='predicted_revenue', \n",
    "        color='predicted_revenue',\n",
    "        color_continuous_scale='RdYlGn', \n",
    "        size_max=25, \n",
    "        zoom=12, \n",
    "        mapbox_style='carto-positron',\n",
    "        hover_data=['commercial_traffic_score', 'road_accessibility_score', 'distance_to_chickfila']\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Commercial Locations Ranked by Revenue Potential\",\n",
    "        height=600\n",
    "    )\n",
    "    \n",
    "    # Location statistics\n",
    "    if len(filtered) > 0:\n",
    "        best = filtered.loc[filtered['predicted_revenue'].idxmax()]\n",
    "        avg_revenue = filtered['predicted_revenue'].mean()\n",
    "        \n",
    "        stats = html.Div([\n",
    "            html.H5(\"Analysis Summary\", className=\"text-primary\"),\n",
    "            html.P(f\"Locations Found: {len(filtered)}\"),\n",
    "            html.P(f\"Average Revenue: ${avg_revenue:,.0f}\"),\n",
    "            html.Hr(),\n",
    "            html.H5(\"Top Location\", className=\"text-success\"),\n",
    "            html.P(f\"üìç {best['latitude']:.4f}, {best['longitude']:.4f}\"),\n",
    "            html.P(f\"üí∞ Revenue: ${best['predicted_revenue']:,.0f}\"),\n",
    "            html.P(f\"üè™ Commercial Score: {best['commercial_traffic_score']:.0f}\"),\n",
    "            html.P(f\"üõ£Ô∏è Road Access: {best['road_accessibility_score']:.0f}\"),\n",
    "            html.P(f\"‚õΩ Gas Station Proximity: {best['gas_station_proximity']:.0f}\"),\n",
    "            html.P(f\"üçó Distance to Chick-fil-A: {best['distance_to_chickfila']:.1f} mi\"),\n",
    "            html.P(f\"üè¢ Competition: {best['fast_food_competition']:.0f}\"),\n",
    "            html.P(f\"üë• Median Age: {best['median_age']:.0f}\"),\n",
    "            html.P(f\"üíµ Median Income: ${best['median_income']:,.0f}\")\n",
    "        ])\n",
    "    else:\n",
    "        stats = html.Div([\n",
    "            html.H5(\"No Locations Found\", className=\"text-warning\"),\n",
    "            html.P(\"Try adjusting your filters to see more locations.\")\n",
    "        ])\n",
    "    \n",
    "    return fig, stats\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29cdddb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
